{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing with the gensim coherence measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out difference 'coherence' pipeline combinations.\n",
    "Topic models: LDA, NNMF, LSA, PCA + varimax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import logging\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "from process_topics import show_topic_words, run_all, coherence_widget, NewCoherence\n",
    "from gensim.models import CoherenceModel, LdaModel, HdpModel, nmf, LdaMulticore\n",
    "from gensim.corpora import Dictionary, csvcorpus\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import *\n",
    "from time import time\n",
    "warnings.filterwarnings('ignore')  # To ignore all warnings that arise here to enhance clarity\n",
    "from ipywidgets import interact, interactive, IntSlider, Layout, interact_manual, fixed, interactive_output, FloatSlider\n",
    "import ipywidgets as widgets\n",
    "import qgrid\n",
    "import logging\n",
    "\n",
    "#logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up test corpus, should be tokenized, sotpwords removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 74.6 ms, total: 3.59 s\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# my_csv = pd.read_csv('..\\..\\wiki_movie_plots_deduped.csv')\n",
    "# plots = my_csv['Plot']\n",
    "elections = io.open('Election2008Paragraphes.txt',encoding = \"ISO-8859-1\")\n",
    "electionlines  =elections.readlines()\n",
    "\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(),  strip_punctuation, strip_multiple_whitespaces, strip_numeric,remove_stopwords, strip_short]\n",
    "\n",
    "texts = [preprocess_string(line, filters=CUSTOM_FILTERS) for line in electionlines]\n",
    "\n",
    "\n",
    "dictionary = Dictionary(texts)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "data = [texts, dictionary, corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffdcf3a1d9654b0ea44d3325b7c440e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "aW50ZXJhY3RpdmUoY2hpbGRyZW49KFJhZGlvQnV0dG9ucyhkZXNjcmlwdGlvbj11J0Nob29zZSBNb2RlbCcsIGxheW91dD1MYXlvdXQod2lkdGg9dScyNTBweCcpLCBvcHRpb25zPSgnTk1GJyzigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#changes made to FARotate in the code will require kernel restart if reloading this cell!\n",
    "m = coherence_widget(data)\n",
    "display(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics, coherences, both= m.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>care health insurance plan costs quality americans families companies veterans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>america world people today global energy nation future work like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>need energy world oil security change national nuclear military time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>people know american want going think good said got like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>government american federal people security economy way time trust spending</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>iraq troops military war iran president qaeda afghanistan security plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>president country want states believe time united going change thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>war time world years like bush end going said americans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tax jobs families help taxes workers americans working middle economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>new energy jobs create nuclear york years like time use</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Topic\n",
       "0  care health insurance plan costs quality americans families companies veterans\n",
       "1                america world people today global energy nation future work like\n",
       "2            need energy world oil security change national nuclear military time\n",
       "3                        people know american want going think good said got like\n",
       "4     government american federal people security economy way time trust spending\n",
       "5         iraq troops military war iran president qaeda afghanistan security plan\n",
       "6            president country want states believe time united going change thank\n",
       "7                         war time world years like bush end going said americans\n",
       "8           tax jobs families help taxes workers americans working middle economy\n",
       "9                         new energy jobs create nuclear york years like time use"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a00394bd39f545b1bf55a94c572fdde9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VkJveChjaGlsZHJlbj0oSW50U2xpZGVyKHZhbHVlPTEwLCBkZXNjcmlwdGlvbj11J3cnLCBsYXlvdXQ9TGF5b3V0KGhlaWdodD11JzMwcHgnLCB3aWR0aD11JzEwMDBweCcpLCBtYXg9MTAwMCnigKY=\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e65efd8caa4f04b47656756d12b5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height=u'500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from process_topics import coherence_scores\n",
    "from similarity import *\n",
    "style = {'width': '1000px', 'height': '30px'}\n",
    "\n",
    "w=IntSlider(10,0,1000, description = 'w',layout=style)\n",
    "w2=IntSlider(10,0,1000, description = 'w2',layout=style) \n",
    "co=IntSlider(10,0,1000, description = 'co',layout=style)\n",
    "ndocs=IntSlider(1000,0,10000, description = 'ndocs',layout=style)\n",
    "print co.value\n",
    "exp = FloatSlider(value=0.0, min=0, max=20, description='exp', layout=style)\n",
    "joint = FloatSlider(value=0.0, min=0, max=20, description='exp', layout=style)\n",
    "\n",
    "exp.style.handle_color= 'yellow'\n",
    "#print widgets.__dict__\n",
    "ui = widgets.VBox([w, w2, co, ndocs,exp])\n",
    "\n",
    "    \n",
    "def similarities(w,w2,co,ndocs, held=[]):\n",
    "    scores = calculate_sims(w,w2,co,ndocs,'all')\n",
    "    #held.append(w)\n",
    "    display(pd.DataFrame(scores))\n",
    "    return scores\n",
    "\n",
    "out =interactive_output(similarities,\n",
    "         {'w':w,'w2':w2,'co':co,'ndocs':ndocs})\n",
    "\n",
    "out.layout.height= '500px'\n",
    "display(ui,out)\n",
    "\n",
    "@out.capture()\n",
    "def set_exp_per_rest(change):\n",
    "    print (w.value+ w2.value)/ ndocs.value\n",
    "    exp.value = ((w.value+ w2.value)/ ndocs.value) *100\n",
    "    print exp.value \n",
    "    \n",
    "w.observe(set_exp_per_rest, names=\"value\")\n",
    "w2.observe(set_exp_per_rest, names=\"value\")\n",
    "co.observe(set_exp_per_rest, names=\"value\")\n",
    "ndocs.observe(set_exp_per_rest, names=\"value\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " year democratic unionists face historic choice share political power nationalist community\n",
      "year meet hope mother prayer taken government hands ireland road permanent peace\n",
      "yeats said long sacrifice stone heart wait hearts turn stone challenge political leaders follow lincoln called better angels nature century look forward write new chapter irish history\n",
      "want thank honor know mother loved adored awards given makes feel totally worthy mother eyes\n",
      "occur\n",
      "[[0 0 0 0 0 0 0 0 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 1 0 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 0 0 0 1 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 0 1 0 1]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0]]\n",
      "cooccur\n",
      "0 adored       1 angels       2 awards       3 better       4 called       5 century      6 challenge    7 chapter      8 choice       9 community    10 democratic  11 eyes        12 face        13 feel        14 follow      15 forward     16 given       17 government  18 hands       19 heart       20 hearts      21 historic    22 history     23 honor       24 hope        25 ireland     26 irish       27 know        28 leaders     29 lincoln     30 long        31 look        32 loved       33 makes       34 meet        35 mother      36 nationalist  37 nature      38 new         39 peace       40 permanent   41 political   42 power       43 prayer      44 road        45 sacrifice   46 said        47 share       48 stone       49 taken       50 thank       51 totally     52 turn        53 unionists   54 wait        55 want        56 worthy      57 write       58 year        59 yeats       \n",
      "adored adored\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "angels awards\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "awards called\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "better challenge\n",
      "1.0 0.0 eucl  0.0\n",
      "called choice\n",
      "1.0 0.0 eucl  0.0\n",
      "century democratic\n",
      "1.0 0.0 eucl  0.0\n",
      "challenge face\n",
      "1.0 0.0 eucl  0.0\n",
      "chapter follow\n",
      "0.0591312395989 0.940868760401 eucl  5.9160797831\n",
      "choice given\n",
      "1.0 0.0 eucl  0.0\n",
      "community hands\n",
      "1.0 0.0 eucl  0.0\n",
      "democratic hearts\n",
      "0.0 1.0 eucl  5.0\n",
      "eyes history\n",
      "0.0 1.0 eucl  5.0\n",
      "face hope\n",
      "0.0 1.0 eucl  5.0\n",
      "feel irish\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "follow leaders\n",
      "1.0 0.0 eucl  0.0\n",
      "forward long\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "given loved\n",
      "0.077151674981 0.922848325019 eucl  4.89897948557\n",
      "government meet\n",
      "1.0 0.0 eucl  0.0\n",
      "hands nationalist\n",
      "0.0 1.0 eucl  6.16441400297\n",
      "heart new\n",
      "1.0 0.0 eucl  0.0\n",
      "hearts permanent\n",
      "0.0591312395989 0.940868760401 eucl  5.9160797831\n",
      "historic power\n",
      "0.0591312395989 0.940868760401 eucl  5.9160797831\n",
      "history road\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "honor said\n",
      "0.077151674981 0.922848325019 eucl  4.89897948557\n",
      "hope stone\n",
      "1.0 0.0 eucl  0.0\n",
      "ireland thank\n",
      "0.0 1.0 eucl  6.16441400297\n",
      "irish turn\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "know wait\n",
      "0.0 1.0 eucl  6.32455532034\n",
      "leaders worthy\n",
      "1.0 0.0 eucl  0.0\n",
      "lincoln year\n",
      "1.0 0.0 eucl  0.0\n",
      "long"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-108-b6973065cca4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mcooccur\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcooccur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mtf_feature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf_feature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcooccur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcooccur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'eucl '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcooccur\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcooccur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(threshold=np.inf, linewidth=1000)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1500)\n",
    "pd.set_option('display.column_space', 2)\n",
    "\n",
    "texts2 = [preprocess_string(line, filters=CUSTOM_FILTERS) for line in e[1:5]]\n",
    "for tex in texts2:\n",
    "    print ' '.join(tex)\n",
    "tf_vectorizer = CountVectorizer()\n",
    "tftexts = [' '.join(text) for text in texts2]\n",
    "tf = tf_vectorizer.fit_transform(tftexts)\n",
    "tf[tf>1]=1\n",
    "\n",
    "xc = (tf.T * tf)\n",
    "print 'occur'\n",
    "print tf.toarray()\n",
    "print 'cooccur'\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "for i,name in enumerate(tf_feature_names):\n",
    "    width = 12\n",
    "    spacer =width - (len(str(i)) + len(name))\n",
    "    if i-1%10==0 or i==0:\n",
    "        print i,name,' '*spacer,\n",
    "    else:\n",
    "        print i,name,' '*spacer,\n",
    "print ''\n",
    "cooccur =xc.todense()\n",
    "for i,x in enumerate(cooccur):\n",
    "    print tf_feature_names[i],tf_feature_names[i+i]\n",
    "    print float(cosine_similarity(x,cooccur[i+1])), float(cosine_distances(x,cooccur[i+1])), 'eucl ', float(euclidean_distances(x,cooccur[i+1]))\n",
    "display(pd.DataFrame(cooccur))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
